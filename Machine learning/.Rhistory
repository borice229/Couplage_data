Generate_output(N, Output_Curves$a[i], Output_Curves$b[i], Output_Curves$c[i], Output_Curves$U0[i])
})
# Affichage de la DataFrame
head(Output_Curves)
# Génération des résultats et création de la DataFrame
Main_Learning_Base <- data.frame(
a = sim_a,
b = sim_b,
c = sim_c,
U0 = sim_U0
)
# Calcul des sorties Un et ajout comme une colonne
Main_Learning_Base$Un <- lapply(1:nrow(Main_Learning_Base), function(i) {
# Générer les valeurs de Un avec Generate_output
generated_values <- Generate_output(N, Main_Learning_Base$a[i], Main_Learning_Base$b[i], Main_Learning_Base$c[i], Main_Learning_Base$U0[i])
generated_values[-1] <- generated_values[-1] + rnorm(N, mean = 0, sd = 1)
return(generated_values)
})
# Établir la connexion
con <- dbConnect(RMySQL::MySQL(),
dbname = "Mlearn",  # Nom de la base de données
host = "127.0.0.1",    # Adresse locale du serveur MySQL
port = 3306,           # Port par défaut pour MySQL
user = "root",         # Nom d'utilisateur
password = "less@intsARS19") # Mot de passe réel
# Vérification de la connexion
if (!is.null(con)) {
cat("Connexion réussie à la base de données 'mlearning' !\n")
} else {
cat("Erreur lors de la connexion.\n")
}
param<-Main_Learning_Base[, 1:4]
# Créer la table Parameters
dbExecute(con, "
CREATE TABLE IF NOT EXISTS Parameters (
id INT AUTO_INCREMENT PRIMARY KEY,
a FLOAT NOT NULL,
b FLOAT NOT NULL,
c FLOAT NOT NULL,
U0 FLOAT NOT NULL
)
")
# Créer la table NormalData avec l'ID comme clé primaire et la clé étrangère pour parameter_id
dbExecute(con, "
CREATE TABLE IF NOT EXISTS NormalData (
id INT AUTO_INCREMENT PRIMARY KEY,  -- Définir id comme clé primaire
parameter_id INT NOT NULL,          -- Clé étrangère
Un JSON NOT NULL,                   -- Colonne JSON pour stocker Un
FOREIGN KEY (parameter_id) REFERENCES Parameters(id) ON DELETE CASCADE  -- Référence à Parameters
)
")
# Créer la table NoiseData
dbExecute(con, "
CREATE TABLE IF NOT EXISTS NoiseData (
id INT AUTO_INCREMENT PRIMARY KEY,
parameter_id INT NOT NULL,
Un JSON NOT NULL,
FOREIGN KEY (parameter_id) REFERENCES Parameters(id) ON DELETE CASCADE
)
")
# Désactiver les contraintes de clé étrangère
dbExecute(con, "SET foreign_key_checks = 0")
# Vider la table Parameters
dbExecute(con, "TRUNCATE TABLE Parameters")
# Réactiver les contraintes de clé étrangère
dbExecute(con, "SET foreign_key_checks = 1")
# Préparer les données à insérer, en excluant l'`id`
for (i in 1:nrow(param)) {
query <- sprintf("INSERT INTO Parameters (a, b, c, U0) VALUES (%f, %f, %f, %f)",
param$a[i], param$b[i], param$c[i], param$U0[i])
dbExecute(con, query)
}
# Créer la colonne 'parameter_id' qui contient des valeurs de 1 à N
Output_Curves$parameter_id <- 1:nrow(Output_Curves)
# Préparer les données à insérer dans la table NormalData
for (i in 1:nrow(Output_Curves)) {
# Convertir la colonne Un en chaîne JSON
Un_json <- toJSON(Output_Curves$Un[[i]], auto_unbox = TRUE)  # auto_unbox pour convertir en un tableau JSON correct
# Construire la requête SQL
query <- sprintf("INSERT INTO NormalData (parameter_id, Un) VALUES (%d, '%s')",
Output_Curves$parameter_id[i], Un_json)  # '%s' pour insérer la chaîne JSON
# Exécuter la requête d'insertion
dbExecute(con, query)
}
# Créer la colonne 'parameter_id' qui contient des valeurs de 1 à N
Main_Learning_Base$parameter_id <- 1:nrow(Main_Learning_Base)
# Préparer les données à insérer dans la table NormalData
for (i in 1:nrow(Main_Learning_Base)) {
# Convertir la colonne Un en chaîne JSON
Un_j <- toJSON(Main_Learning_Base$Un[[i]], auto_unbox = TRUE)  # auto_unbox pour convertir en un tableau JSON correct
# Construire la requête SQL
query <- sprintf("INSERT INTO NoiseData (parameter_id, Un) VALUES (%d, '%s')",
Main_Learning_Base$parameter_id[i], Un_j)  # '%s' pour insérer la chaîne JSON
# Exécuter la requête d'insertion
dbExecute(con, query)
}
# Supposons que Main_Learning_Base est déjà chargé et contient M lignes
set.seed(123)  # Pour la reproductibilité
# Déterminer le nombre de lignes pour chaque ensemble
train_size <- floor(0.7 * M)  # 70% pour l'entraînement
test_size <- M - train_size     # 30% pour le test
# Échantillonner les indices pour l'ensemble d'entraînement
train_indices <- sample(1:M, size = train_size, replace = FALSE)
# Créer les ensembles d'entraînement et de test
Main_Training_Base <- Main_Learning_Base[train_indices, ]  # Ensemble d'entraînement
Main_Test_Base <- Main_Learning_Base[-train_indices, ]      # Ensemble de test
Uo <- c(8.21, 1.572, 3.197)
a1<-1.72
b1<-2.72
c1<-0.80
# Vérifier et mettre à jour la base
for (u0 in Uo) {
# Vérifier si les paramètres (a, b, c, U0) existent déjà dans `param`
existing_row <- param[param$a == a1 & param$b == b1 & param$c == c1 & param$U0 == u0, ]
if (nrow(existing_row) == 0) {  # Si les paramètres n'existent pas déjà
# Ajouter les paramètres dans `param`
new_param <- data.frame(a = a1, b = b1, c = c1, U0 = u0)
param <- rbind(param, new_param)
Nparam <-nrow(param)
# Générer la suite avec bruit
U_val_bruité <- Generate_output(N, a1, b1, c1, u0)
U_val_bruité[-1]<-U_val_bruité[-1]+ rnorm(N,mean=0,sd=1)
# Ajouter les données dans Main_Learning_Base
new_row <- data.frame(a = a1, b = b1, c = c1, U0 = u0, Un = I(list(U_val_bruité)), parameter_id = Nparam)
Main_Learning_Base <- rbind(Main_Learning_Base, new_row)
# Générer la suite sans bruit
U_val <- Generate_output(N, a1, b1, c1, u0)
# Ajouter les données dans Output_Curves
new_curve <- data.frame(a = a1, b = b1, c = c1, U0 = u0, Un = I(list(U_val)), parameter_id = Nparam)
Output_Curves <- rbind(Output_Curves, new_curve)
}
}
RelDiff <- function(y_observe, y_pred) {
return(rowMeans(abs(y_observe - y_pred)))
}
test_RelDiff <- function() {
# Définir des valeurs d'observation et prédites
y_observe <- matrix(c(1, 2, 3, 4), nrow = 2, byrow = TRUE)
y_pred <- matrix(c(1, 2.5, 3, 4.5), nrow = 2, byrow = TRUE)
# Résultat attendu : moyenne des différences absolues
waited <- c(0.25, 0.25)
# Appel de la fonction RelDiff
fun_out <- RelDiff(y_observe, y_pred)
# Comparer les résultats attendus avec ceux obtenus
if(all(waited==fun_out)){
return("OK")
}else{
return("Error...")
}
}
# Appel de la fonction de test
test_RelDiff()
f_obj <- function(A, B, C) {
# Filtrer les lignes de la base principale
filtered_row <- subset(Main_Training_Base, a == A & b == B & c == C)
if (nrow(filtered_row) == 0) {
return(paste0('les paramètres renseignés ne sont pas dans la base')) # Retourner une valeur élevée si aucun filtre ne correspond
}
y_obser <- do.call(rbind, lapply(filtered_row$Un, function(x) unlist(x)))
# Déterminer N comme la longueur totale de `y_obser`
N<- ncol(y_obser)-1
# Générer les prédictions
y_pred <- t(mapply(Generate_output, N, A, B, C, filtered_row[, 4]))
# Calculer l'écart
ecart <- RelDiff(y_obser, y_pred)
return(ecart)
}
test_f_obj <- function() {
# Définir les valeurs des paramètres pour le test
A <- 3.09
B <- 4.43
C <- 0.70
# Résultat attendu pour ces paramètres
waited <- 0.8520035
# Appeler la fonction f_obj avec les paramètres donnés
fun_out <- f_obj(A, B, C)
# Comparer le résultat de la fonction avec le résultat attendu
if (all.equal(fun_out, waited, tolerance = 1e-6)) {
return("OK")
} else {
return("Error...")
}
}
# Appeler la fonction de test
test_f_obj()
#train parameters
params<-Main_Training_Base[, 1:3]
# Define the objective function to minimize
objectif <- function(p) {
A <- p[1]
B <- p[2]
C <- p[3]
n<-nrow(p)
fun <- 0
for (i in n ) {
fun <- fun + f_obj(A[i,], B[i,], C[i,])
}
fun
}
# Définir les bornes pour les paramètres a, b, et c
bornes_inf <- c(min(params$a), min(params$b), min(params$c))  # Bornes inférieures
bornes_sup <- c(max(params$a), max(params$b), max(params$c))  # Bornes supérieures
# Mesurer le temps pour l'ajustement avec le modèle-données
start_time <- Sys.time()
# Apply the DIRECT algorithm to optimize the parameters
resultat <- direct(fn = objectif, lower = bornes_inf, upper = bornes_sup, control = list(print.level = 1))
end_time <- Sys.time()
computation_time_data_coupling <- end_time - start_time
cat("Temps de calcul pour l'ajustement modèle-données : ", computation_time_data_coupling, " secondes.\n")
# Print the results (optimized parameters a, b, c)
print(resultat$par)  # Optimized values of a, b, and c
#set.seed(123)  # Pour garantir la reproductibilité du tirage
Sampl_train <- Main_Training_Base[sample(nrow(Main_Training_Base), 50, replace = TRUE), ]
param_spl<-Sampl_train[,1:3]
# Définir les bornes pour les paramètres a, b, et c
bornes_inf_spl <- c(min(param_spl$a), min(param_spl$b), min(param_spl$c))  # Bornes inférieures
bornes_sup_spl <- c(max(param_spl$a), max(param_spl$b), max(param_spl$c))  # Bornes supérieures
# Apply the DIRECT algorithm to optimize the parameters
resultat_spl <- direct(fn = objectif, lower = bornes_inf_spl, upper = bornes_sup_spl, control = list(print.level = 1))
# Print the results (optimized parameters a, b, c)
print(resultat_spl$par)  # Optimized values of a, b, and c
# Créer un tableau vide pour stocker les résultats des 10 itérations
results_table <- data.frame(a = numeric(10), b = numeric(10), c = numeric(10))
# Répéter l'opération 10 fois
for (i in 1:10) {
# Tirage aléatoire avec remise de 50 courbes
indices <- sample(nrow(Main_Training_Base), 50, replace = TRUE)
Newbase_spl <- Main_Training_Base[indices, ]
param_sp<-Newbase_spl[,1:3]
# Définir les bornes pour les paramètres a, b, et c
bornes_inf_sp <- c(min(param_sp$a), min(param_sp$b), min(param_sp$c))  # Bornes inférieures
bornes_sup_sp <- c(max(param_sp$a), max(param_sp$b), max(param_sp$c))  # Bornes   supérieures
# Appliquer l'algorithme DIRECT pour ajuster les paramètres
resultat_sp <- direct(fn = objectif, lower = bornes_inf_sp, upper = bornes_sup_sp, control = list(print.level = 0))
# Stocker les résultats des paramètres optimisés dans le tableau
results_table[i, ] <- round(resultat_sp$par,2)
}
# Afficher le tableau contenant les valeurs des 10 triplets
print(results_table)
# Calcul de la moyenne, de la variance et de l'écart-type relatifs
moyenne <- colMeans(results_table)
variance <- apply(results_table, 2, var)
ecart_type <- sqrt(variance)
# Calcul de la variance relative et de l'écart-type relatif
# Variance relative = variance / (moyenne^2)
variance_relative <- variance / (moyenne^2)
# Ecart-type relatif = écart-type / moyenne
ecart_type_relatif <- ecart_type / moyenne
# Afficher les résultats
resultats_statistiques <- data.frame(
Moyenne = round(moyenne,2),
Variance_Relative = variance_relative,
Ecart_Type_Relatif = round(ecart_type_relatif,2)
)
print(resultats_statistiques)
a_dj<-3
b_dj<-4.18
c_dj<-0.62
out_size<-40
# Fonction pour calculer le MAE pour chaque ligne
calculate_mae_per_row <- function(y_real_data, y_pred_data) {
# Vérifier que les dimensions des matrices correspondent
if (nrow(y_real_data) != nrow(y_pred_data)) {
stop("Les matrices y_real_data et y_pred_data doivent avoir le même nombre de lignes.")
}
# Calcul du MAE pour chaque ligne
mae_per_row <- apply(cbind(y_real_data, y_pred_data), 1, function(row) {
# Extraire la ligne de valeurs réelles et prédites
y_real <- row[1:ncol(y_real_data)]
y_pred <- row[(ncol(y_real_data) + 1):length(row)]
# Calcul de l'erreur absolue pour la ligne
mae <- mean(abs(y_real - y_pred))
return(mae)
})
# Calcul de la moyenne des MAE
mae_global <- mean(mae_per_row)
return(mae_global)
}
# Exemple d'utilisation
# Matrices de valeurs réelles et prédites (par exemple 3 observations avec 2 variables)
y_real_data <- do.call(rbind, lapply(Main_Training_Base$Un, function(x) unlist(x)))
y_pred_data <- t(mapply( Generate_output ,out_size,a_dj, b_dj ,c_dj, Main_Training_Base$U0))
# Calcul du MAE global
mae_train <- calculate_mae_per_row(y_real_data, y_pred_data)
# Affichage du résultat
print(paste("Le MAE train est :", mae_train))
a_dj<-3
b_dj<-4.18
c_dj<-0.62
out_size<-40
# Exemple d'utilisation
# Matrices de valeurs réelles et prédites (par exemple 3 observations avec 2 variables)
y_real_test <- do.call(rbind, lapply(Main_Test_Base$Un, function(x) unlist(x)))
y_pred_test <- t(mapply( Generate_output ,out_size,a_dj, b_dj ,c_dj, Main_Test_Base$U0))
# Calcul du MAE global
mae_test <- calculate_mae_per_row(y_real_test, y_pred_test)
# Affichage du résultat
print(paste("Le MAE test est :", mae_test))
sgd <- function(y_observe_list, U0_list, N, learning_rate, max_iter) {
# Initialisation des paramètres
a <- 0  # Initialisation dans l'intervalle [2, 5]
b <- 0  # Initialisation dans l'intervalle [1, 5]
c <- 0  # Initialisation dans l'intervalle [0.1, 0.9]
cost_history <- numeric(max_iter)  # Stockage des coûts
for (iter in 1:max_iter) {
# Sélection d'un exemple aléatoire
i <- sample(1:length(U0_list), 1)
U0 <- U0_list[[i]]
y_observe <- y_observe_list[i, ]
# Calculer les prédictions
y_pred <- Generate_output(N, a, b, c, U0)
# Calcul des gradients
grad_a <- sum(2 * (y_pred - y_observe) * U0^c) / length(y_observe)
grad_b <- sum(2 * (y_pred - y_observe)) / length(y_observe)
grad_c <- sum(2 * (y_pred - y_observe) * log(U0) * a * U0^c) / length(y_observe)
# Mise à jour des paramètres avec contraintes
a <- max(min(a - learning_rate * grad_a, max(params$a)), min(params$a))
b <- max(min(b - learning_rate * grad_b, max(params$b)), min(params$b))
c <- max(min(c - learning_rate * grad_c, max(params$c)), min(params$c))
# Calcul du coût
cost <- sum((y_pred - y_observe)^2) / length(y_observe)
cost_history[iter] <- cost
# Afficher le coût toutes les 100 itérations
if (iter %% 100 == 0) {
cat("Iteration:", iter, " Cost:", cost,
" a:", a, " b:", b, " c:", c, "\n")
}
}
return(list(a = a, b = b, c = c, cost_history = cost_history))
}
start_time <- Sys.time()
N <- 40
U0_list <- Main_Training_Base$U0  # Liste des valeurs initiales
y_observe_list <- do.call(rbind, lapply(Main_Training_Base$Un, function(x) unlist(x)))  # Matrice des observations
learning_rate <- 0.001
max_iter <- 1000
result <- sgd(y_observe_list, U0_list, N, learning_rate, max_iter)
end_time <- Sys.time()
computation_time_sgd <- end_time - start_time
cat("Temps de calcul pour l'ajustement SGD : ", computation_time_sgd, " secondes.\n")
# Plage des paramètres
param_ranges <- list(a = c(min(params$a), max(params$a)), b = c(min(params$b), max(params$b)), c = c(min(params$c), max(params$c)))
# Fonction pour initialiser aléatoirement les paramètres
random_init <- function(param_ranges) {
list(
a = runif(1, param_ranges$a[1], param_ranges$a[2]),
b = runif(1, param_ranges$b[1], param_ranges$b[2]),
c = runif(1, param_ranges$c[1], param_ranges$c[2])
)
}
# Stocker les résultats des 5 tests
results <- list()
for (test in 1:5) {
cat("\n--- Test", test, "---\n")
# Initialisation aléatoire
init_params <- random_init(param_ranges)
# Ajuster les valeurs initiales dans la fonction
result <- sgd(
y_observe_list = y_observe_list,
U0_list = U0_list,
N = N,
learning_rate = learning_rate,
max_iter = max_iter
)
# Stocker les résultats
results[[test]] <- list(
a_final = result$a,
b_final = result$b,
c_final = result$c,
cost_history = result$cost_history
)
}
# Extraire les paramètres finaux pour chaque test
a_vals <- sapply(results, function(res) res$a_final)
b_vals <- sapply(results, function(res) res$b_final)
c_vals <- sapply(results, function(res) res$c_final)
# Fonction pour calculer les métriques
compute_metrics <- function(values) {
mean_val <- mean(values)  # Moyenne
variance <- var(values)   # Variance
std_dev <- sd(values)     # Écart-type
variance_relative <- variance / mean_val
std_dev_relative <- std_dev / mean_val
list(
mean = round(mean_val,2),
variance_relative = variance_relative,
std_dev_relative = std_dev_relative
)
}
# Calculer les métriques pour chaque paramètre
metrics_a <- compute_metrics(a_vals)
metrics_b <- compute_metrics(b_vals)
metrics_c <- compute_metrics(c_vals)
cbind(metrics_a,metrics_b,metrics_c)
a_sgd<-2.09
b_sgd<-1.09
c_sgd<-0.28
out_size<-40
# Exemple d'utilisation
# Matrices de valeurs réelles et prédites (par exemple 3 observations avec 2 variables)
y_real_data_sgd <- do.call(rbind, lapply(Main_Training_Base$Un, function(x) unlist(x)))
y_pred_data_sgd <- t(mapply( Generate_output ,out_size,a_sgd, b_sgd ,c_sgd, Main_Training_Base$U0))
# Calcul du MAE global
mae_train_sgd <- calculate_mae_per_row(y_real_data_sgd, y_pred_data_sgd)
# Affichage du résultat
print(paste("Le MAE Train sgd est :", mae_train_sgd))
# Exemple d'utilisation
# Matrices de valeurs réelles et prédites (par exemple 3 observations avec 2 variables)
y_real_test_sgd <- do.call(rbind, lapply(Main_Test_Base$Un, function(x) unlist(x)))
y_pred_test_sgd <- t(mapply( Generate_output ,out_size,a_sgd, b_sgd ,c_sgd, Main_Test_Base$U0))
# Calcul du MAE global
mae_test_sgd <- calculate_mae_per_row(y_real_test_sgd, y_pred_test_sgd)
# Affichage du résultat
print(paste("Le MAE Test sgd est :", mae_test_sgd))
ML_data<-head(Main_Learning_Base,-3)
Learn_data <- ML_data%>%
# Décomposer la liste Un en plusieurs lignes
unnest(Un) %>%
# Ajouter une nouvelle colonne avec le numéro de courbe
mutate(Ncurve = rep(1:nrow(ML_data), times = sapply(ML_data$Un, length))) %>%
# Ajouter l'indice n pour chaque élément dans Un
group_by(Ncurve) %>%
mutate(n = row_number()) %>%
ungroup() %>%
select(Ncurve, n, U0, TS = Un)
Ntrain<-0.3*100*41
# Construire Train_Base_1 avec les 30% premières lignes
Train_Base_1 <- Learn_data[1:Ntrain, ]
Test_Base_1<-Learn_data[(Ntrain + 1):nrow(Learn_data) , ]
S <- function(TrainB, TestB) {
# Initialisation des matrices
TrainB_S <- matrix(0, nrow = nrow(TrainB), ncol = ncol(TrainB))
TestB_S <- matrix(0, nrow = nrow(TestB), ncol = ncol(TestB))
# Boucle sur les colonnes 2 à 4
for (i in 2:ncol(TrainB)) {
# Mise à l'échelle de TrainB
TrainB_S[, i] <- ((TrainB[, i] - colMeans(TrainB[, i])) / diff(range(TrainB[, i])))[,1]
# Mise à l'échelle de TestB (en utilisant les paramètres de TrainB)
TestB_S[, i] <- ((TestB[, i] - colMeans(TrainB[, i])) / diff(range(TrainB[, i])))[,1]
}
# Retourner une liste avec les matrices mises à l'échelle
return(list(TrainB_S, TestB_S))
}
# Appel de la fonction et assignation des résultats
LearnBase_S <- S(Train_Base_1, Test_Base_1)
TrainBase_S <- as.data.frame(LearnBase_S[[1]])
TestBase_S <- as.data.frame(LearnBase_S[[2]])
# Attribution des noms de colonnes
colnames(TrainBase_S) <- c("n curve", "n", "U0", "TS")
colnames(TestBase_S) <- c("n curve", "n", "U0", "TS")
p<-2 # le nombre d'inputs
# Créer le modèle séquentiel
model <- keras_model_sequential() %>%
layer_dense(units = 3, activation = "relu",input_shape = c(p)) %>%
layer_dense(units = 6, activation = "relu") %>%
layer_dense(units = 3, activation = "relu") %>%
layer_dense(units = 1, activation = "linear")
p<-2 # le nombre d'inputs
# Créer le modèle séquentiel
model <- keras_model_sequential() %>%
layer_dense(units = 3, activation = "relu",input_shape = p) %>%
layer_dense(units = 6, activation = "relu") %>%
layer_dense(units = 3, activation = "relu") %>%
layer_dense(units = 1, activation = "linear")
keras3::install_keras()
p<-2 # le nombre d'inputs
# Créer le modèle séquentiel
model <- keras_model_sequential() %>%
layer_dense(units = 3, activation = "relu",input_shape = p) %>%
layer_dense(units = 6, activation = "relu") %>%
layer_dense(units = 3, activation = "relu") %>%
layer_dense(units = 1, activation = "linear")
library(keras3)
model %>% compile(
optimizer = optimizer_rmsprop(),
loss = "mse",  # Mean Squared Error pour la régression
metrics = c("mae")  # Mean Absolute Error comme métrique
)
summary(model)
renv::status()
library(keras3)
renv::remove("keras")
renv::status()
library(keras3)
library(ggplot2)
library(tidyr)
library(tidyverse)
library(reshape2)
library(dplyr)
library(DBI)
library(RMySQL)
library(jsonlite)
library(nloptr)
library(reticulate)
library(tensorflow)
library(keras3)
install.packages("gridExtra")
library(gridExtra)
library(gridExtra)
library(ggplot2)
library(tidyr)
library(tidyverse)
library(reshape2)
library(dplyr)
library(DBI)
library(RMySQL)
library(jsonlite)
library(nloptr)
library(reticulate)
library(tensorflow)
library(keras3)
library(gridExtra)
